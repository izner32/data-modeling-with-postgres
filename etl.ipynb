{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download necessary libraries - only do this once \n",
    "# import sys\n",
    "# !{sys.executable} -m pip install psycopg2 \n",
    "# !{sys.executable} -m pip install pandas \n",
    "# !{sys.executable} -m pip install numpy\n",
    "\n",
    "# Import necessary libraries\n",
    "import os \n",
    "import glob # used to search for a specific file pattern \n",
    "import psycopg2 # for connecting to postgres database\n",
    "import numpy as np # great substitute for array \n",
    "import pandas as pd # to be able to use dataframe which is utilized during transformation(staging) stage \n",
    "from table_queries import * # to call the sql queries we made\n",
    "from dotenv import load_dotenv, find_dotenv # to access the secret keys we've hidden in a separate file \n",
    "\n",
    "load_dotenv(find_dotenv()) # grab values inside env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to database\n",
    "#### create a function that grabs the values inside your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to database \n",
    "conn = psycopg2.connect(host=\"localhost\", port=\"5432\",database=\"sparkifydb\",user=\"postgres\",password=os.getenv(\"DB_PASSWORD\"))\n",
    "cur = conn.cursor() # used to execute sql queries\n",
    "\n",
    "# create a function that grabs the values inside your data \n",
    "def get_files(filepath):\n",
    "    all_files = [] \n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Song Data\n",
    "#### processing song_data dataset to be able to insert values at songs and artists dimensional tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_songs</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARD7TVE1187B99BFB1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California - LA</td>\n",
       "      <td>Casual</td>\n",
       "      <td>SOMZWCG12A8C13C480</td>\n",
       "      <td>I Didn't Mean To</td>\n",
       "      <td>218.93179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_songs           artist_id  artist_latitude  artist_longitude  \\\n",
       "0          1  ARD7TVE1187B99BFB1              NaN               NaN   \n",
       "\n",
       "   artist_location artist_name             song_id             title  \\\n",
       "0  California - LA      Casual  SOMZWCG12A8C13C480  I Didn't Mean To   \n",
       "\n",
       "    duration  year  \n",
       "0  218.93179     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraction \n",
    "song_data = get_files(\"data/song_data\") \n",
    "\n",
    "filepath = song_data[0]\n",
    "\n",
    "# loading - creating a dataframe(think of this as temporary storage) to transform and clean the data \n",
    "df = pd.read_json(filepath, lines=True)\n",
    "df.head()\n",
    "\n",
    "# transformation - we are supposed to do some transformations but the dataset is already good enough, so yeah thats it \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. songs table \n",
    "#### performing etl to be able to insert values at songs table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction & transformation - grabbing data and only getting the columns we want\n",
    "songs_df = df[[\"song_id\",\"title\",\"artist_id\",\"year\",\"duration\"]]\n",
    "\n",
    "for i,row in songs_df.iterrows():\n",
    "    # loading - putting data inside the sparkifydb inside songs table \n",
    "    cur.execute(songs_dimension_insert, list(row))\n",
    "    conn.commit() # we pretty much need to do this at every query execution :(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. artists table\n",
    "#### performing etl to be able to insert values at artists table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              song_id             title           artist_id  year   duration\n",
      "0  SOMZWCG12A8C13C480  I Didn't Mean To  ARD7TVE1187B99BFB1     0  218.93179\n"
     ]
    }
   ],
   "source": [
    "# extraction & transformation - grabbing data and only getting the columns we want\n",
    "artists_df = df[[\"artist_id\",\"artist_name\",\"artist_location\",\"artist_latitude\",\"artist_longitude\"]]\n",
    "artists_df.head()\n",
    "\n",
    "for i,row in artists_df.iterrows():\n",
    "    # loading - putting data inside the sparkifydb inside songs table \n",
    "    cur.execute(artists_dimension_insert, list(row))\n",
    "    conn.commit() # we pretty much need to do this at every query execution :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Log Data\n",
    "#### processing log_data dataset to be able to insert values at users and time dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Walter</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Frye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>San Francisco-Oakland-Hayward, CA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1540919166796</td>\n",
       "      <td>38</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541105830796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Summers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106106796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist       auth firstName gender  itemInSession lastName  length level  \\\n",
       "0   None  Logged In    Walter      M              0     Frye     NaN  free   \n",
       "1   None  Logged In    Kaylee      F              0  Summers     NaN  free   \n",
       "\n",
       "                            location method  page   registration  sessionId  \\\n",
       "0  San Francisco-Oakland-Hayward, CA    GET  Home  1540919166796         38   \n",
       "1        Phoenix-Mesa-Scottsdale, AZ    GET  Home  1540344794796        139   \n",
       "\n",
       "   song  status             ts  \\\n",
       "0  None     200  1541105830796   \n",
       "1  None     200  1541106106796   \n",
       "\n",
       "                                           userAgent  userId  \n",
       "0  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...      39  \n",
       "1  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraction \n",
    "log_data = get_files(\"data/log_data\") \n",
    "\n",
    "filepath = log_data[0]\n",
    "\n",
    "# loading - creating a dataframe(think of this as temporary storage) to transform and clean the data \n",
    "df = pd.read_json(filepath, lines=True)\n",
    "df.head(2)\n",
    "\n",
    "# transformation - we are supposed to do some transformations but the dataset is already good enough, so yeah thats it \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. time table\n",
    "#### performing etl to be able to insert values at time table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_13404/3282001989.py:12: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  time_data = list((t, t.dt.hour, t.dt.day, t.dt.weekofyear, t.dt.month, t.dt.year, t.dt.weekday)) # .dt is used to get only the specific part in a datetime | e.g. dt.week only grabs the week value from the datetime\n"
     ]
    }
   ],
   "source": [
    "# extraction \n",
    "df = df.query(\"page == 'NextSong'\") # SELECT * FROM time WHERE page = 'NextSong'\n",
    "df.head()\n",
    "\n",
    "# transformation\n",
    "# grab only the ts column, we'll be extracting the correct columns for time table from that column alone \n",
    "# to_datetime converts a timestamp into a human understandable datetime format\n",
    "t = pd.to_datetime(df['ts'], unit='ms') \n",
    "df['ts'] = pd.to_datetime(df['ts'], unit='ms')\n",
    "\n",
    "# dividing the datetime into different columns including hour,day,etc. \n",
    "time_data = list((t, t.dt.hour, t.dt.day, t.dt.weekofyear, t.dt.month, t.dt.year, t.dt.weekday)) # .dt is used to get only the specific part in a datetime | e.g. dt.week only grabs the week value from the datetime \n",
    "column_labels = list(('start_time', 'hour', 'day', 'week', 'month', 'year', 'weekday')) # this is just another way of creating list\n",
    "\n",
    "# convert the timestamp into a proper dataframe with columns that we want\n",
    "# zip - returns a zip object where first item from the first argument is paired into the first item from the second argument, and so on.. item with no pair is ignored \n",
    "# dict - converts into a dictionary | if you pass a [(1, 'Geeks'), (2, 'For)] it would turn into {1: 'Geeks', 2: 'For'}\n",
    "# from_dict - convert dictionary into rows | returns a dataframe | e.g. \n",
    "    # data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
    "    # >>> pd.DataFrame.from_dict(data, orient='index')\n",
    "    #        0  1  2  3\n",
    "    # row_1  3  2  1  0\n",
    "    # row_2  a  b  c  d\n",
    "time_df =  pd.DataFrame.from_dict(dict(zip(column_labels, time_data))) # \n",
    "time_df.head()\n",
    "\n",
    "# loading \n",
    "for i, row in time_df.iterrows():\n",
    "    cur.execute(time_dimension_insert, list(row))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. users table\n",
    "#### performing etl to be able to insert values at users table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction & transformation - grabbing data and only getting the columns we want\n",
    "users_df = df[[\"userId\", \"firstName\", \"lastName\", \"gender\", \"level\"]]\n",
    "users_df.head()\n",
    "\n",
    "for i,row in users_df.iterrows():\n",
    "    # loading \n",
    "    cur.execute(users_dimension_insert, list(row))\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfb4883d108fc92ac768439090a2e92bb9a1f760a54beeecfd6762b5dcd70fe3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
