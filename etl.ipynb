{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download necessary libraries - only do this once \n",
    "# import sys\n",
    "# !{sys.executable} -m pip install psycopg2 \n",
    "# !{sys.executable} -m pip install pandas \n",
    "# !{sys.executable} -m pip install numpy\n",
    "\n",
    "# Import necessary libraries\n",
    "import os \n",
    "import glob # used to search for a specific file pattern \n",
    "import psycopg2 # for connecting to postgres database\n",
    "import numpy as np # great substitute for array \n",
    "import pandas as pd # to be able to use dataframe which is utilized during transformation(staging) stage \n",
    "from table_queries import * # to call the sql queries we made\n",
    "from dotenv import load_dotenv, find_dotenv # to access the secret keys we've hidden in a separate file \n",
    "\n",
    "load_dotenv(find_dotenv()) # grab values inside env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to database\n",
    "#### create a function that grabs the values inside your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to database \n",
    "conn = psycopg2.connect(host=\"localhost\", port=\"5432\",database=\"sparkifydb\",user=\"postgres\",password=os.getenv(\"DB_PASSWORD\"))\n",
    "cur = conn.cursor() # used to execute sql queries\n",
    "\n",
    "# create a function that grabs the values inside your data \n",
    "def get_files(filepath):\n",
    "    all_files = [] \n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Song Data\n",
    "#### processing song_data dataset to be able to insert values at songs and artists dimensional tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_songs</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARD7TVE1187B99BFB1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California - LA</td>\n",
       "      <td>Casual</td>\n",
       "      <td>SOMZWCG12A8C13C480</td>\n",
       "      <td>I Didn't Mean To</td>\n",
       "      <td>218.93179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_songs           artist_id  artist_latitude  artist_longitude  \\\n",
       "0          1  ARD7TVE1187B99BFB1              NaN               NaN   \n",
       "\n",
       "   artist_location artist_name             song_id             title  \\\n",
       "0  California - LA      Casual  SOMZWCG12A8C13C480  I Didn't Mean To   \n",
       "\n",
       "    duration  year  \n",
       "0  218.93179     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraction \n",
    "song_data = get_files(\"data/song_data\") \n",
    "\n",
    "filepath = song_data[0]\n",
    "\n",
    "# loading - creating a dataframe(think of this as temporary storage) to transform and clean the data \n",
    "df = pd.read_json(filepath, lines=True)\n",
    "df.head()\n",
    "\n",
    "# transformation - we are supposed to do some transformations but the dataset is already good enough, so yeah thats it \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### songs table \n",
    "#### performing etl to songs dataframe to be able to insert values at songs table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction & transformation - grabbing data and only getting the columns we want\n",
    "songs_df = df[[\"song_id\",\"title\",\"artist_id\",\"year\",\"duration\"]]\n",
    "\n",
    "for i,row in songs_df.iterrows():\n",
    "    # loading - putting data inside the sparkifydb inside songs table \n",
    "    cur.execute(songs_dimension_insert, list(row))\n",
    "    conn.commit() # we pretty much need to do this at every query execution :(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### artists table\n",
    "#### performing etl to artists dataframe to be able to insert values at artists table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              song_id             title           artist_id  year   duration\n",
      "0  SOMZWCG12A8C13C480  I Didn't Mean To  ARD7TVE1187B99BFB1     0  218.93179\n"
     ]
    }
   ],
   "source": [
    "# extraction & transformation - grabbing data and only getting the columns we want\n",
    "artists_df = df[[\"artist_id\",\"artist_name\",\"artist_location\",\"artist_latitude\",\"artist_longitude\"]]\n",
    "artists_df.head()\n",
    "\n",
    "for i,row in artists_df.iterrows():\n",
    "    # loading - putting data inside the sparkifydb inside songs table \n",
    "    cur.execute(artists_dimension_insert, list(row))\n",
    "    conn.commit() # we pretty much need to do this at every query execution :(\n",
    "    print(songs_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfb4883d108fc92ac768439090a2e92bb9a1f760a54beeecfd6762b5dcd70fe3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
